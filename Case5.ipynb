{"cells":[{"cell_type":"markdown","metadata":{"id":"MSt0etXkqw0_"},"source":["### AUTH"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"L013EJevNETg","executionInfo":{"status":"ok","timestamp":1715347398533,"user_tz":240,"elapsed":13602,"user":{"displayName":"GARRETT CHRISMAN","userId":"13084771020881301321"}}},"outputs":[],"source":["# Cloud authentication.\n","from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-jYj0ZmvNMh6","executionInfo":{"status":"ok","timestamp":1715347400416,"user_tz":240,"elapsed":1886,"user":{"displayName":"GARRETT CHRISMAN","userId":"13084771020881301321"}}},"outputs":[],"source":["# Import, authenticate and initialize the Earth Engine library.\n","import ee\n","ee.Authenticate()\n","ee.Initialize(project='ee-USERNAME/PROJECT')"]},{"cell_type":"markdown","metadata":{"id":"n_Rv36f8q1RQ"},"source":["### **Geometries**"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"zpR0HOeGhxnG","executionInfo":{"status":"ok","timestamp":1715347401567,"user_tz":240,"elapsed":1154,"user":{"displayName":"GARRETT CHRISMAN","userId":"13084771020881301321"}}},"outputs":[],"source":["import ee\n","import folium\n","from IPython.display import HTML\n","\n","#Initialize the Earth Engine API\n","ee.Initialize()\n","\n","#Define the study area\n","geometryPINEGULCH = ee.Geometry.Polygon(\n","        [[[-108.80164742558028, 39.28402267340665],\n","          [-108.23722481815841, 39.29358857295844],\n","          [-108.23997140018966, 39.56831366828538],\n","          [-108.79752755253341, 39.553491364366145]\n","          ]])\n","\n","geometryGRIZZLYCREEK = ee.Geometry.Polygon(\n","        [[[-107.40066503796388, 39.69746161256133],\n","          [-107.39860510144044, 39.46619798632684],\n","          [-106.90834020886231, 39.46778823854969],\n","          [-106.96670507702638, 39.74763415825682],\n","          [-107.40272497448731, 39.73337830588799]\n","          ]])\n","\n","geometryCHERRYCANYON = ee.Geometry.Polygon(\n","        [[[-103.53011965523325, 37.51499254964799],\n","          [-103.53011965523325, 37.336135915833296],\n","          [-103.33785891304575, 37.33176822282621],\n","          [-103.33785891304575, 37.519349567331446]]]);\n","\n","geometrySILVERCREEK = ee.Geometry.Polygon(\n","        [[[-105.29672060223413, 37.6911297494477],\n","          [-105.29672060223413, 37.35348518722596],\n","          [-104.96850404949976, 37.35348518722596],\n","          [-104.96850404949976, 37.6911297494477]]]);\n","# 2017-07-19\n","\n","geometryDECKER = ee.Geometry.Polygon(\n","        [[[-106.02963654395263, 38.479133428395656],\n","          [-106.02963654395263, 38.38392784402862],\n","          [-105.91977326270263, 38.38392784402862],\n","          [-105.91977326270263, 38.479133428395656]]]);\n","\n","# 2019-09-08\n","\n","geometryLAKECHRIST = ee.Geometry.Polygon(\n","        [[[-107.09745152809535, 39.473198422531205],\n","          [-107.09745152809535, 39.36445604809376],\n","          [-106.97797520973597, 39.36445604809376],\n","          [-106.97797520973597, 39.473198422531205]]]);\n","#2018-07-30\n","\n","geometryPALATEAU = ee.Geometry.Polygon(\n","        [[[-108.55952873183622, 37.67620981411429],\n","          [-108.55952873183622, 37.534774582410634],\n","          [-108.39198722792997, 37.534774582410634],\n","          [-108.39198722792997, 37.67620981411429]]]);\n","\n","\n","geometries_dict = {\n","    'PineGulch': geometryPINEGULCH,\n","    'GrizzlyCreek': geometryGRIZZLYCREEK,\n","    'CherryCanyon': geometryCHERRYCANYON,\n","    'SilverCreek': geometrySILVERCREEK,\n","    'Decker': geometryDECKER,\n","    'LakeChrist': geometryLAKECHRIST,\n","    'Palateau': geometryPALATEAU\n","}\n","\n","geometries = [\n","    geometryPINEGULCH,\n","    geometryGRIZZLYCREEK,\n","    geometryCHERRYCANYON,\n","    geometrySILVERCREEK,\n","    geometryDECKER,\n","    geometryLAKECHRIST,\n","    geometryPALATEAU\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zq7sAc0Gm8pO"},"outputs":[],"source":["def get_fire_boundary(event_id):\n","    dataset = ee.FeatureCollection('USFS/GTAC/MTBS/burned_area_boundaries/v1')\n","    filtered_dataset = dataset.filter(ee.Filter.eq('Event_ID', event_id))\n","\n","    if filtered_dataset.size().getInfo() > 0:\n","        selected_fire = ee.Feature(filtered_dataset.first())\n","        fire_geometry = selected_fire.geometry()\n","        geometry_type = fire_geometry.type().getInfo()\n","\n","        if geometry_type == 'Polygon':\n","            coordinates = fire_geometry.coordinates().getInfo()\n","            fire_polygon = ee.Geometry.Polygon(coordinates)\n","            return fire_polygon\n","        elif geometry_type == 'GeometryCollection':\n","            geometries = fire_geometry.geometries().getInfo()\n","            fire_multipolygon = ee.Geometry.MultiPolygon(geometries)\n","            return fire_multipolygon\n","        else:\n","            print(f\"Unsupported geometry type: {geometry_type}\")\n","            return None\n","    else:\n","        print(f\"No features found with the specified Event_ID: {event_id}\")\n","        return None\n","\n","\n","event_id_PineGulch = 'CO3933610852620200731'\n","event_id_GrizzlyCreek = 'CO3957210726620200810'\n","event_id_CherryCanyon = 'CO3736710345020200520'\n","event_id_Decker = 'CO3840910600420190908'\n","event_id_LakeChrist = 'CO3937110704320180703'\n","event_id_Palateau = 'CO3765810847420180722'\n","event_id_SilverCreek = 'CO4022310665520180719'\n","\n","\n","event_id_dict = {\n","    'PineGulch': 'CO3933610852620200731',\n","    'GrizzlyCreek': 'CO3957210726620200810',\n","    'CherryCanyon': 'CO3736710345020200520',\n","    'Decker': 'CO3840910600420190908',\n","    'LakeChrist': 'CO3937110704320180703',\n","    'Palateau': 'CO3765810847420180722',\n","    'SilverCreek': 'CO4022310665520180719'\n","}\n","\n","fire_boundaries = {}\n","\n","#for fire_name, event_id in event_id_dict.items():\n","#    fire_boundary = get_fire_boundary(event_id)\n","#\n","#    if fire_boundary is not None:\n","#        fire_boundaries[fire_name] = fire_boundary\n","#        print(f\"Added fire boundary for {fire_name} to the fire_boundaries dictionary:\")\n","#        print(fire_boundaries[fire_name].getInfo())\n","\n","for fire_name, polygon in geometries_dict.items():\n","    #fire_boundary = get_fire_boundary(polygon)\n","\n","    if polygon is not None:\n","        fire_boundaries[fire_name] = polygon\n","        print(f\"Added fire boundary for {fire_name} to the fire_boundaries dictionary:\")\n","        print(fire_boundaries[fire_name].getInfo())"]},{"cell_type":"markdown","metadata":{"id":"1mlC5EHSq6wm"},"source":["### **DATES**"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"E5a30lg1h7ch","executionInfo":{"status":"ok","timestamp":1715347423474,"user_tz":240,"elapsed":132,"user":{"displayName":"GARRETT CHRISMAN","userId":"13084771020881301321"}}},"outputs":[],"source":["fire_dates = {\n","    'PineGulch': {\n","        'prefire_start': '2020-05-20',\n","        'prefire_end': '2020-06-18',\n","        'postfire_start': '2020-09-20',\n","        'postfire_end': '2020-10-28'\n","    },\n","    'GrizzlyCreek': {\n","        'prefire_start': '2020-05-20',\n","        'prefire_end': '2020-07-18',\n","        'postfire_start': '2020-09-06',\n","        'postfire_end': '2020-11-01'\n","    },\n","    'CherryCanyon':{\n","        'prefire_start': '2020-04-20',\n","        'prefire_end': '2020-05-15',\n","        'postfire_start': '2020-07-01',\n","        'postfire_end': '2020-08-15'\n","    },\n","    'SilverCreek': { #Done\n","        'prefire_start': '2021-06-01',\n","        'prefire_end': '2021-08-10',\n","        'postfire_start': '2019-05-10',\n","        'postfire_end': '2019-06-30'\n","    },\n","    'Decker': { # Kinda - not a huge fan of.... shadowing due to mountains east to west\n","        'prefire_start': '2019-05-30',\n","        'prefire_end': '2019-07-25',\n","       'postfire_start': '2020-5-10',\n","       'postfire_end': '2020-6-20'\n","    },\n","    'LakeChrist': { # done\n","        'prefire_start': '2017-08-01',\n","        'prefire_end': '2017-10-15',\n","        'postfire_start': '2018-09-15',\n","        'postfire_end': '2018-10-30'\n","    },\n","    'Palateau': { #Done\n","        'prefire_start': '2018-05-10',\n","        'prefire_end': '2018-06-20',\n","        'postfire_start': '2019-05-10',\n","        'postfire_end': '2019-06-20'\n","    }\n","}\n","\n","fire_names = [\n","    'PineGulch',\n","    'GrizzlyCreek',\n","    'CherryCanyon',\n","    'Decker',\n","    'LakeChrist',\n","    'Palateau',\n","    'SilverCreek'\n","]"]},{"cell_type":"markdown","metadata":{"id":"_egZfcS5xmnV"},"source":["### **READ and SPLIT IMAGE**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNHF3cM1iH-w"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import os\n","from osgeo import gdal\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as mcolors\n","from google.colab import drive\n","from skimage.filters import threshold_minimum\n","import numpy as np\n","\n","def split_image_into_patches(image, patch_size, overlap_factor=2):\n","    height, width = image.shape\n","    patches = []\n","    stride = patch_size // overlap_factor\n","    for i in range(0, height - patch_size + 1, stride):\n","        for j in range(0, width - patch_size + 1, stride):\n","            patch = image[i:i+patch_size, j:j+patch_size]\n","            patches.append(patch)\n","    return np.array(patches)\n","\n","#def split_image_into_patches_test(image, patch_size): No overlap for test\n","def split_image_into_patches_test(image, patch_size):\n","    height, width = image.shape\n","    patches = []\n","    stride = patch_size  #No overlap\n","    for i in range(0, height - patch_size + 1, stride):\n","        for j in range(0, width - patch_size + 1, stride):\n","            patch = image[i:i+patch_size, j:j+patch_size]\n","            patches.append(patch)\n","    return np.array(patches)\n","\n","def read_geotiff(file_path):\n","    dataset = gdal.Open(file_path, gdal.GA_ReadOnly)\n","    if dataset is None:\n","        print(f\"Failed to open file: {file_path}\")\n","        return None\n","    if dataset.RasterCount < 1:\n","        print(f\"No raster bands found in file: {file_path}\")\n","        return None\n","    band = dataset.GetRasterBand(1)\n","    data = band.ReadAsArray()\n","    return data\n","\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"r7FBN0g6wwwG"},"source":["### **PATCHING**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"U9_QurdpOzg7","executionInfo":{"status":"ok","timestamp":1715351969857,"user_tz":240,"elapsed":3,"user":{"displayName":"GARRETT CHRISMAN","userId":"13084771020881301321"}}},"outputs":[],"source":["#pip install scikit-image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjZav6Kh9wDP"},"outputs":[],"source":["from skimage.filters import threshold_minimum\n","from scipy.ndimage import median_filter\n","from scipy.ndimage import uniform_filter\n","from scipy.ndimage import gaussian_filter\n","import cv2 as cv\n","import numpy as np\n","\n","google_drive_path = \"/content/drive/MyDrive/Cleaned_Fire_images_TIFF\"\n","os.chdir(google_drive_path)\n","\n","patch_size = 256\n","threshold = 85\n","\n","def normalize_image(image, epsilon=1e-10):\n","    min_val = np.min(image)\n","    max_val = np.max(image)\n","    range_val = max_val - min_val\n","    if range_val == 0:\n","        return image\n","    else:\n","        range_safe = np.maximum(range_val, epsilon)\n","        return (image - min_val) / range_safe\n","\n","def enhance_changes(image, threshold=0.5, factor=100, power=0.5):\n","\n","    image_scaled = image * factor\n","\n","\n","    image_transformed = np.where(image_scaled < (threshold * factor),\n","                                 np.power(image_scaled, power),\n","                                 image_scaled)\n","\n","    image_transformed /= factor\n","\n","    return image_transformed\n","\n","\n","def extract_central_patch(image, size= (6 * 256)):\n","    height, width = image.shape\n","    top_left_x = (width - size) // 2\n","    top_left_y = (height - size) // 2\n","    return image[top_left_y:top_left_y+size, top_left_x:top_left_x+size]\n","\n","import numpy as np\n","\n","from collections import Counter\n","\n","def classify_patch(patch):\n","    total_pixels = patch.size\n","    burned_pixels = np.sum(patch)\n","\n","    burned_percentage = (burned_pixels / total_pixels) * 100\n","\n","    if burned_percentage > 75:\n","        return \"mostly burned\"\n","    elif 50 < burned_percentage <= 75:\n","        return \"half burned\"\n","    elif 25 < burned_percentage <= 50:\n","        return \"less burned\"\n","    elif 10 < burned_percentage <= 25:\n","        return \"vaguely burned\"\n","    else:\n","        return \"not burned\"\n","\n","def apply_denoising(image):\n","    # Parameters can be tuned based on image characteristics\n","    return cv.fastNlMeansDenoising(image, None, 30, 11, 31)\n","\n","\n","selected_images = ['PineGulch','SilverCreek'] #'PineGulch','LakeChrist',\"Decker\",\n","#selected_images = fire_names\n","dnbr_images = []\n","ground_truth_images = []\n","for fire_name in selected_images:\n","\n","    file_path = f'S1/RATIO/S1_ratio_{fire_name}.tif'\n","    dnbr_image = read_geotiff(file_path)\n","\n","    # Case 2&3 data Aug. and Box\n","    dnbr_image = extract_central_patch(dnbr_image)\n","    dnbr_image = enhance_changes(dnbr_image)\n","\n","    dnbr_image = apply_denoising(dnbr_image.astype(np.uint8))\n","    dnbr_image = normalize_image(dnbr_image)\n","\n","    dnbr_image_focal = dnbr_image\n","\n","    #Pay attention to what S2 image you pull from\n","    binary_ground_truth_image = read_geotiff(f'S2/Resized_S2/TEST/resized_S2_{fire_name}_test.tif')\n","    binary_ground_truth_image1 = extract_central_patch(binary_ground_truth_image)\n","    binary_ground_truth_image2 = normalize_image(binary_ground_truth_image1)\n","    binary_ground_truth_image_threshold = (binary_ground_truth_image2 > 0.45).astype(np.uint8)\n","\n","    #print(dnbr_image.shape)\n","    #print(binary_ground_truth_image_threshold.shape)\n","\n","    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n","\n","    axes[0].imshow(dnbr_image_focal, cmap='gray')\n","    axes[0].set_title('DNBR Image')\n","    axes[0].axis('off')\n","\n","    axes[1].imshow(binary_ground_truth_image_threshold, cmap='gray')\n","    axes[1].set_title('Ground Truth Image')\n","    axes[1].axis('off')\n","\n","    print(threshold)\n","    print(dnbr_image_focal[:5, :5])\n","    print(binary_ground_truth_image_threshold[:5, :5])\n","\n","    # Split the dNBR image and ground truth image into patches with overlap\n","    dnbr_patches = split_image_into_patches(dnbr_image_focal, patch_size, overlap_factor=2)\n","    ground_truth_patches = split_image_into_patches(binary_ground_truth_image_threshold, patch_size, overlap_factor=2)\n","\n","\n","    classifications_truth = [classify_patch(patch) for patch in ground_truth_patches]\n","    distribution_truth = Counter(classifications_truth)\n","    print(f\"{distribution_truth} - Ground Truth\")\n","\n","    classifications = [classify_patch(patch) for patch in dnbr_patches]\n","    distribution_b = Counter(classifications)\n","    print(f\"{distribution_b} - dNBR\")\n","\n","\n","    print(dnbr_patches.shape)\n","    print(ground_truth_patches.shape)\n","\n","    dnbr_images.append(dnbr_patches)\n","    ground_truth_images.append(ground_truth_patches)\n","\n","dnbr_images = np.concatenate(dnbr_images)\n","ground_truth_images = np.concatenate(ground_truth_images)\n","\n","print(dnbr_images.shape)\n","print(ground_truth_images.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"rWdAqd0dywx5"},"source":["DATA AUGMENTATION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"saAuGvIpy0EN"},"outputs":[],"source":["labels, values = zip(*distribution_truth.items())\n","indices = np.arange(len(labels))\n","width = 1\n","\n","plt.bar(indices, values, width)\n","plt.xticks(indices, labels, rotation=45)\n","plt.ylabel('Number of Patches')\n","plt.title('Distribution of Burn Classifications')\n","plt.tight_layout()\n","plt.show()\n","\n","labels, values = zip(*distribution_b.items())\n","indices = np.arange(len(labels))\n","width = 1\n","\n","plt.bar(indices, values, width)\n","plt.xticks(indices, labels, rotation=45)\n","plt.ylabel('Number of Patches')\n","plt.title('Distribution of Burn Classifications')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6DOt-lGA7f_m"},"outputs":[],"source":["from imgaug import augmenters as iaa\n","import numpy as np\n","\n","# Define your augmentation sequence\n","augmenter = iaa.Sequential([\n","    iaa.Fliplr(0.5),  # horizontal flips\n","    iaa.Flipud(0.5),  # vertical flips\n","    iaa.Affine(rotate=(0, 360))  # rotate between 0 and 90 degrees\n","])\n","\n","def apply_augmentation_pairwise(dnbr_set, ground_truth_set, num_repeats=3):\n","    augmented_dnbr = []\n","    augmented_ground_truth = []\n","\n","    for _ in range(num_repeats):  # Repeat the augmentation process num_repeats times\n","        for dnbr_img, gt_img in zip(dnbr_set, ground_truth_set):\n","            # Apply the same augmentation to both images\n","            aug_det = augmenter.to_deterministic()  # ensures the same augmentation is applied to both images\n","            augmented_dnbr.append(aug_det.augment_image(dnbr_img))\n","            augmented_ground_truth.append(aug_det.augment_image(gt_img))\n","\n","    return np.array(augmented_dnbr), np.array(augmented_ground_truth)\n","\n","# Assuming dnbr_images and ground_truth_images are defined elsewhere in your code\n","original_dnbr_tile_count = dnbr_images.shape[0]\n","original_ground_truth_tile_count = ground_truth_images.shape[0]\n","\n","print(\"Number of original dNBR tiles:\", original_dnbr_tile_count)\n","print(\"Number of original ground truth tiles:\", original_ground_truth_tile_count)\n","\n","# Apply augmentations, tripling the dataset size\n","augmented_dnbr_images, augmented_ground_truth_images = apply_augmentation_pairwise(dnbr_images, ground_truth_images, num_repeats=3)\n","\n","# Print out the new distribution\n","print(\"Number of augmented dNBR tiles:\", len(augmented_dnbr_images))\n","print(\"Number of augmented ground truth tiles:\", len(augmented_ground_truth_images))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V7Ly1CQz-9vE"},"outputs":[],"source":["c_dnbr_images = np.concatenate((dnbr_images, augmented_dnbr_images))\n","c_ground_truth_images = np.concatenate((ground_truth_images, augmented_ground_truth_images))\n","\n","print(\"Total number of dNBR tiles (original + augmented):\", c_dnbr_images.shape[0])\n","print(\"Total number of ground truth tiles (original + augmented):\", c_ground_truth_images.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"241Prxvdusya"},"outputs":[],"source":["plt.figure(figsize=(6, 6))\n","plt.hist(c_dnbr_images.flatten(), bins=50, color='blue', alpha=0.7)\n","plt.title('DNBR Image Histogram')\n","plt.xlabel('Pixel Value')\n","plt.ylabel('Frequency')\n","plt.show()\n","\n","# Create a new figure for the binary_ground_truth_image histogram\n","plt.figure(figsize=(6, 6))\n","plt.hist(c_ground_truth_images.flatten(), bins=50, color='green', alpha=0.7)\n","plt.title('S2 Raw Image Histogram')\n","plt.xlabel('Pixel Value')\n","plt.ylabel('Frequency')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"0zMt0Xz1B0yI"},"source":["### ***Looking at patches and effectivness ***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7CECz3Z7kMr"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# patches\n","dnbr_patches_sample = c_dnbr_images[:10]\n","ground_truth_patches_sample = c_ground_truth_images[:10]\n","\n","fig, axes = plt.subplots(10, 2, figsize=(10, 50))\n","\n","for i in range(10):\n","    # Show dNBR patch\n","    ax = axes[i, 0]\n","    ax.imshow(dnbr_patches_sample[i], cmap='gray')\n","    ax.set_title(f'dNBR patch {i}')\n","\n","    # Show ground truth patch\n","    ax = axes[i, 1]\n","    ax.imshow(ground_truth_patches_sample[i], cmap='gray')\n","    ax.set_title(f'Ground truth patch {i}')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpsS1FDz9BhI"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","threshold = 0.45\n","\n","#dnbr_image = read_geotiff(file_path)\n","\n","print(\"Minimum dNBR value:\", np.min(dnbr_image))\n","print(\"Maximum dNBR value:\", np.max(dnbr_image))\n","print(\"Mean (Average) dNBR value:\", np.mean(dnbr_image))\n","print(\"Standard Deviation (SD) of dNBR:\", np.std(dnbr_image))\n","print(\"Median dNBR value:\", np.median(dnbr_image))\n","print(\"Sum of dNBR values:\", np.sum(dnbr_image))\n","print(\"Variance of dNBR values:\", np.var(dnbr_image))\n","\n","#Histo\n","plt.hist(dnbr_image.flatten(), bins=50, color='c')\n","plt.title(\"Histogram of dNBR values\")\n","plt.show()\n","\n","#binary_ground_truth_image_threshold = (binary_ground_truth_image > threshold).astype(np.uint8)\n","binary_ground_truth_image_threshold\n","\n","#Vis\n","plt.imshow(binary_ground_truth_image_threshold, cmap='gray')\n","plt.title(\"Binary Ground Truth Image\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UnIz3_dxJvF5"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from ipywidgets import widgets, interactive\n","\n","def update(threshold):\n","    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n","\n","    # dNBR image thresholded\n","    dnbr_image_t = (dnbr_image > threshold).astype(np.uint8)\n","    ax = axes[0]\n","    ax.imshow(dnbr_image_t, cmap='gray')\n","    ax.set_title('dNBR Image Thresholded')\n","\n","    # Ground truth thresholded\n","    binary_ground_truth_image_t = (binary_ground_truth_image > threshold).astype(np.uint8)\n","    ax = axes[1]\n","    ax.imshow(binary_ground_truth_image_t, cmap='gray')\n","    ax.set_title('Ground Truth Image Thresholded')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Create interactive slider\n","threshold_slider = widgets.FloatSlider(\n","    value=0.5,\n","    min=0,\n","    max=1,\n","    step=0.05,\n","    description='Threshold:',\n","    continuous_update=False\n",")\n","\n","# Display the widget\n","interactive(update, threshold=threshold_slider)\n"]},{"cell_type":"markdown","metadata":{"id":"IGVLl4saw8gG"},"source":["### **CNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZeMW5CMwZu9"},"outputs":[],"source":["print(len(c_dnbr_images))\n","print(len(c_ground_truth_images))\n","\n","print(len(dnbr_patches))\n","print(len(ground_truth_patches))"]},{"cell_type":"code","source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Input, Conv2DTranspose, concatenate\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import BinaryCrossentropy\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import Lambda, Input\n","\n","from tensorflow.keras.models import load_model\n","\n","#unet_model = create_unet_model()\n","#loaded_model = load_model('/content/drive/MyDrive/Cleaned_Fire_images_TIFF/Case1:BaseCase/unet_model_case1.5.30_RES.h5')\n","#unet_model = loaded_model\n","#combined_model  = loaded_model"],"metadata":{"id":"CLPOy_zD9FAi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lhqqM5xwNaJa"},"outputs":[],"source":["def learning_rate_schedule(epoch):\n","    if epoch < 28:\n","        return 0.00001  # first 30 epochs\n","    else:\n","        return 0.000001  # last 20 epochs\n","\n","def create_unet_model(input_shape=(256,256, 1)):\n","    inputs = Input(shape=input_shape)\n","\n","    # Encoder\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    c1 = BatchNormalization()(c1)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","    p1 = Dropout(0.25)(p1)\n","\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n","    c2 = BatchNormalization()(c2)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","    p2 = Dropout(0.25)(p2)\n","\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n","    c3 = BatchNormalization()(c3)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","    p3 = Dropout(0.25)(p3)\n","\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n","    c4 = BatchNormalization()(c4)\n","    p4 = MaxPooling2D((2, 2))(c4)\n","    p4 = Dropout(0.25)(p4)\n","\n","    # Bottom\n","    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n","    b = BatchNormalization()(b)\n","\n","    # Decoder\n","    u1 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(b)\n","    u1 = concatenate([u1, c4])\n","    u1 = Dropout(0.25)(u1)\n","    d1 = Conv2D(512, (3, 3), activation='relu', padding='same')(u1)\n","    d1 = BatchNormalization()(d1)\n","\n","    u2 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(d1)\n","    u2 = concatenate([u2, c3])\n","    u2 = Dropout(0.25)(u2)\n","    d2 = Conv2D(256, (3, 3), activation='relu', padding='same')(u2)\n","    d2 = BatchNormalization()(d2)\n","\n","    u3 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(d2)\n","    u3 = concatenate([u3, c2])\n","    u3 = Dropout(0.25)(u3)\n","    d3 = Conv2D(128, (3, 3), activation='relu', padding='same')(u3)\n","    d3 = BatchNormalization()(d3)\n","\n","    u4 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(d3)\n","    u4 = concatenate([u4, c1])\n","    u4 = Dropout(0.25)(u4)\n","    d4 = Conv2D(64, (3, 3), activation='relu', padding='same')(u4)\n","    d4 = BatchNormalization()(d4)\n","\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid')(d4)\n","\n","    model = Model(inputs=inputs, outputs=outputs)\n","   # model.compile(optimizer=Adam(learning_rate=0.00001), loss=BinaryCrossentropy(from_logits=False), metrics=['binary_accuracy'])\n","    return model\n","\n","lr_scheduler = LearningRateScheduler(learning_rate_schedule)\n","unet_model = create_unet_model()\n","\n","unet_model.compile(optimizer=Adam(learning_rate=0.00001),  # Start with initial learning rate\n","                   loss=BinaryCrossentropy(from_logits=False),\n","                   metrics=['binary_accuracy'])\n","\n","# Train the model\n","X_train, X_test, y_train, y_test = train_test_split(c_dnbr_images, c_ground_truth_images, test_size=0.3)\n","\n","X_train = X_train[..., np.newaxis]\n","X_test = X_test[..., np.newaxis]\n","\n","batch_size = 32\n","epochs = 50\n","model_cnn = unet_model.fit(X_train, y_train,\n","                               batch_size,\n","                               epochs,\n","                               validation_data=(X_test, y_test),\n","                               callbacks=[lr_scheduler])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpypRvGKc0xP"},"outputs":[],"source":["# saving and loading the model\n","from tensorflow.keras.models import load_model\n","\n","#unet_model.save('case5.h5')\n","#combined_model.save('case5.h5')\n","#loaded_model = load_model('.h5')\n","#unet_model = loaded_model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GOw9B6z26-v0"},"outputs":[],"source":["unet_model.summary()\n","#combined_model.summary()\n","#tf.keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"91_SBRjoRHHc"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","pd.DataFrame(model_cnn.history).plot(\n","    figsize=(8, 5), xlim=[0,50], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n","    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n","plt.legend(loc=\"lower left\")  # extra code\n","#save_fig(\"keras_learning_curves_plot\")  # extra code\n","\n","save_path = 'keras_learning_curves_plot_CASE5.png'\n","plt.savefig(save_path, format='png')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2sK0x-ijW0SY"},"outputs":[],"source":["from tensorflow.keras.utils import plot_model\n","plot_model(unet_model, to_file='unet_model_5.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"markdown","metadata":{"id":"gNSBo-mFxGs3"},"source":["### **ReCONSTRUCT IMAGES**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F47M7nHGTjDn"},"outputs":[],"source":["def reconstruct_image_from_patches(patches, original_shape, patch_size, overlap_factor=2):\n","    height, width = original_shape\n","    reconstructed_image = np.zeros(original_shape)\n","    patch_count = np.zeros(original_shape)\n","    stride = patch_size // overlap_factor\n","    patch_idx = 0\n","\n","    for i in range(0, height - patch_size + 1, stride):\n","        for j in range(0, width - patch_size + 1, stride):\n","            reconstructed_image[i:i+patch_size, j:j+patch_size] += patches[patch_idx]\n","            patch_count[i:i+patch_size, j:j+patch_size] += 1\n","            patch_idx += 1\n","\n","    reconstructed_image /= patch_count\n","    return reconstructed_image\n","\n","def reconstruct_image_from_patches_test(patches, original_shape, patch_size):\n","    height, width = original_shape\n","    reconstructed_image = np.zeros(original_shape)\n","    stride = patch_size  #No overlap\n","    patch_idx = 0\n","    for i in range(0, height - patch_size + 1, stride):\n","        for j in range(0, width - patch_size + 1, stride):\n","            reconstructed_image[i:i+patch_size, j:j+patch_size] = patches[patch_idx]\n","            patch_idx += 1\n","\n","    return reconstructed_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YKfFtEHSTjw_"},"outputs":[],"source":["dnbr_images_expanded = c_dnbr_images[..., np.newaxis]\n","predictions = unet_model.predict(dnbr_images_expanded)\n","#predictions = combined_model.predict(dnbr_images_expanded)\n","#Reconstruct the image from the patches\n","predictions = predictions[..., 0]\n","reconstructed_image = reconstruct_image_from_patches(predictions, dnbr_image.shape, patch_size, overlap_factor=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jfS_RPUypUpn"},"outputs":[],"source":["#pip install rasterio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vDESdHEXv3F"},"outputs":[],"source":["from PIL import Image\n","from skimage import exposure\n","\n","def save_image_as_jpeg(image_array, output_path):\n","    image_array = image_array * 500\n","    image_uint8 = Image.fromarray(image_array.clip(0, 255).astype(np.uint8))\n","    image_uint8.save(output_path)\n","\n","\n","import rasterio\n","def save_image_as_tif(image_path, save_path):\n","    with rasterio.open(image_path) as src:\n","        with rasterio.open(save_path, 'w', driver='GTiff',\n","                           width=src.width, height=src.height,\n","                           count=src.count, dtype=src.dtypes[0],\n","                           crs=src.crs, transform=src.transform) as dst:\n","            dst.write(src.read())\n","\n","output_tif_path = 'Case5.tif'\n","output_jpeg_path = 'Case6.jpeg'\n","\n","#save_image_as_tif(reconstructed_image, output_tif_path)\n","save_image_as_jpeg(reconstructed_image, output_jpeg_path)"]},{"cell_type":"markdown","metadata":{"id":"9qLbmQVAxUMf"},"source":["### **RUNNING CNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qi-Xr4zVQGLZ"},"outputs":[],"source":["#https://docs.opencv.org/3.4/d5/d69/tutorial_py_non_local_means.html\n","import cv2 as cv\n","\n","fire_name = fire_names[0]\n","new_image_path = f'S1/RATIO/S1_ratio_{fire_name}.tif'\n","new_image = read_geotiff(new_image_path)\n","\n","# Apply the same preprocessing steps as done for the training images\n","new_image = read_geotiff(new_image_path)\n","preprocessed_new_image = new_image\n","preprocessed_new_image = enhance_changes(preprocessed_new_image)\n","preprocessed_new_image = apply_denoising(preprocessed_new_image.astype(np.uint8))\n","preprocessed_new_image = normalize_image(preprocessed_new_image)\n","\n","# Split the preprocessed image into patches\n","patch_size = 256\n","patches = split_image_into_patches_test(preprocessed_new_image, patch_size)\n","\n","# Apply the trained CNN model to the patches\n","patches_reshaped = patches.reshape(patches.shape[0], patches.shape[1], patches.shape[2], 1)\n","new_image_predictions = unet_model.predict(patches_reshaped)\n","new_image_predictions = new_image_predictions[..., 0]\n","\n","# Reconstruct the image from the predicted patches\n","reconstructed_new_image = reconstruct_image_from_patches_test(new_image_predictions, new_image.shape, patch_size)\n","\n","# Apply a threshold to create a binary mask of burned areas\n","threshold = 0.5 # Option to change model output againt preformance metrics\n","burned_area_mask = (reconstructed_new_image < threshold).astype(np.uint8)\n","\n","# Save the output images\n","# output_tif_path = f'{fire_name}_Case5.{threshold}.tif'\n","output_jpeg_path = f'{fire_name}_Case5.{threshold}.jpeg'\n","save_image_as_jpeg(reconstructed_new_image, output_jpeg_path)\n","\n","# Print statistics about the reconstructed image\n","print(\"Min pixel value:\", np.min(reconstructed_new_image))\n","print(\"Max pixel value:\", np.max(reconstructed_new_image))\n","print(\"Mean pixel value:\", np.mean(reconstructed_new_image))\n","print(\"Standard Deviation:\", np.std(reconstructed_new_image))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mAArxLqp5ony"},"outputs":[],"source":["plt.figure(figsize=(10, 6))\n","plt.hist(reconstructed_new_image.flatten(), bins=30, alpha=0.7)\n","plt.title('Histogram of Pixel Value Distributions')\n","plt.xlabel('Pixel Intensity')\n","plt.ylabel('Frequency')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ndu1XXRSxPwW"},"source":["### **EVALUATIONS**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOyAxKrLwMuW"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from matplotlib.colors import ListedColormap\n","import os\n","from osgeo import gdal\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","google_drive_path = \"/content/drive/MyDrive/Cleaned_Fire_images_TIFF\"\n","os.chdir(google_drive_path)\n","\n","def calculate_metrics(y_true, y_pred):\n","    TP = np.sum((y_true == 1) & (y_pred == 1))\n","    FP = np.sum((y_true == 0) & (y_pred == 1))\n","    TN = np.sum((y_true == 0) & (y_pred == 0))\n","    FN = np.sum((y_true == 1) & (y_pred == 0))\n","\n","    precision = TP / (TP + FP)\n","    recall = TP / (TP + FN)\n","    f1_score = 2 * (precision * recall) / (precision + recall)\n","    iou = TP / (TP + FP + FN)\n","    rel_bias = (TP + FP) / (TP + FN) - 1\n","\n","    return precision, recall, f1_score, iou, rel_bias\n","\n","def trim_images_to_smallest(image1, image2):\n","    shape1 = np.array(image1.shape)\n","    shape2 = np.array(image2.shape)\n","    min_shape = np.minimum(shape1, shape2)\n","    return image1[:min_shape[0], :min_shape[1]], image2[:min_shape[0], :min_shape[1]]\n","\n","def trim_to_ground_truth(ground_truth, predicted):\n","    \"\"\"Crop the predicted image to match the shape of the ground truth.\"\"\"\n","    return ground_truth, predicted[:ground_truth.shape[0], :ground_truth.shape[1]]\n","\n","def center_crop_to_ground_truth(ground_truth, predicted):\n","    \"\"\"Center-crop the predicted image to match the size of the ground truth.\"\"\"\n","    gt_rows, gt_cols = ground_truth.shape\n","    pred_rows, pred_cols = predicted.shape\n","\n","    center_row, center_col = pred_rows // 2, pred_cols // 2\n","    half_gt_rows, half_gt_cols = gt_rows // 2, gt_cols // 2\n","\n","    start_row = max(center_row - half_gt_rows, 0)\n","    end_row = start_row + gt_rows\n","    start_col = max(center_col - half_gt_cols, 0)\n","    end_col = start_col + gt_cols\n","\n","    return ground_truth, predicted[start_row:end_row, start_col:end_col]\n","\n","def normalize_image(image, epsilon=1e-10):\n","    min_val = np.min(image)\n","    max_val = np.max(image)\n","    range_val = max_val - min_val\n","    if range_val == 0:\n","        return image\n","    else:\n","        range_safe = np.maximum(range_val, epsilon)\n","        return (image - min_val) / range_safe\n","\n","def read_geotiff(file_path):\n","    dataset = gdal.Open(file_path, gdal.GA_ReadOnly)\n","    if dataset is None:\n","        print(f\"Failed to open file: {file_path}\")\n","        return None\n","    if dataset.RasterCount < 1:\n","        print(f\"No raster bands found in file: {file_path}\")\n","        return None\n","    band = dataset.GetRasterBand(1)\n","    data = band.ReadAsArray()\n","    return data\n","\n","fires = ['CherryCanyon', 'GrizzlyCreek','PineGulch', 'SilverCreek', \"Decker\", \"LakeChrist\",'Palateau']\n","#fires = ['Palateau']\n","\n","\n","for fire in fires:\n","    dnbr1 = read_geotiff(f'{fire}.tif')\n","    dnbr = normalize_image(dnbr1)\n","\n","    ground_truth = read_geotiff(f'{fire}.tif')\n","    ground_truth1 = normalize_image(ground_truth)\n","    ground_truth_binary = (ground_truth1 > 0.45).astype(np.uint8)\n","\n","    model_output1 = cv2.imread(f'Case5{fire}.jpeg', cv2.IMREAD_GRAYSCALE)\n","\n","    model_output1\n","    model_output_norm = model_output1 / 255.0\n","    model_output = np.round(model_output_norm).astype(np.uint8)\n","\n","\n","    #Discrepancy map\n","    discrepancy_rgb = np.zeros((*ground_truth_binary.shape, 3), dtype=np.uint8)\n","\n","    discrepancy_rgb[np.logical_and(ground_truth_binary == 1, model_output == 1)] = [255, 255, 255]  # white (true unburned)\n","    discrepancy_rgb[np.logical_and(ground_truth_binary == 0, model_output == 0)] = [0, 255, 0]      # green (true burned)\n","    discrepancy_rgb[np.logical_and(ground_truth_binary == 1, model_output == 0)] = [0, 0, 255]      # blue (false positives)\n","    discrepancy_rgb[np.logical_and(ground_truth_binary == 0, model_output == 1)] = [255, 0, 0]      # red (false negatives)\n","\n","\n","    #Vis\n","    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n","\n","    axes[0].imshow(dnbr, cmap='gray')\n","    axes[0].set_title(f'{fire} - dNBR')\n","    axes[0].axis('off')\n","\n","    axes[1].imshow(ground_truth_binary, cmap='gray')\n","    axes[1].set_title(f'{fire} - Ground Truth')\n","    axes[1].axis('off')\n","\n","    axes[2].imshow(model_output, cmap='gray')\n","    axes[2].set_title(f'{fire} - Model Output')\n","    axes[2].axis('off')\n","\n","    im = axes[3].imshow(discrepancy_rgb)\n","    axes[3].set_title(f'{fire} - Discrepancy Map')\n","    axes[3].axis('off')\n","\n","    #Adding custom legend\n","    from matplotlib.lines import Line2D\n","    legend_elements = [Line2D([0], [0], marker='o', color='w', markerfacecolor='white', markersize=10, label='Correct Unburned'),\n","                       Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10, label='Correct Burned'),\n","                       Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='False Burend'),\n","                       Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='False Unburned')]\n","    axes[3].legend(handles=legend_elements, loc='upper right')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    #print(\"Ground Truth Min:\", ground_truth_binary.min(), \"Max:\", ground_truth_binary.max())\n","    #print(\"Model Output Min:\", model_output.min(), \"Max:\", model_output.max())\n","    #print(results_table)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MEYMShjYYYx1"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import cv2\n","\n","metrics_dict = {\n","    'Fire Name': [],\n","    'Threshold': [],\n","    'Precision': [],\n","    'Recall': [],\n","    'F1 Score': [],\n","    'IoU': [],\n","    'Relative Bias': []\n","}\n","\n","fire_names = [\n","   'PineGulch',\n","   'GrizzlyCreek',\n","   'CherryCanyon',\n","    'Decker',\n","    'LakeChrist',\n","    'Palateau',\n","    'SilverCreek'\n","]\n","\n","thresholds = [9] # Possability to add more thresholds depending on images created for evaluation in previous steps.\n","\n","for fire_name in fire_names:\n","    for threshold in thresholds:\n","        ground_truth = read_geotiff(f'S2/Resized_S2/TEST/resized_S2_{fire_name}_test.tif')\n","        ground_truth1 = normalize_image(ground_truth)\n","        ground_truth_binary = (ground_truth1 > 0.45).astype(np.uint8)\n","\n","        model_output1 = cv2.imread(f'Case5{fire}.jpeg', cv2.IMREAD_GRAYSCALE)\n","        print(fire_name, threshold)\n","        model_output_norm = model_output1 / 255.0\n","        model_output_binary = (model_output_norm > 0.5).astype(np.uint8)\n","\n","        #print (model_output_norm)\n","        #print (model_output_binary)\n","\n","        ground_truth_binary, model_output_binary = trim_images_to_smallest(ground_truth_binary, model_output_norm)\n","\n","        precision, recall, f1_score, iou, dice, rel_bias = calculate_metrics(ground_truth_binary, model_output_binary)\n","\n","        metrics_dict['Fire Name'].append(fire_name)\n","        metrics_dict['Threshold'].append(threshold)\n","        metrics_dict['Precision'].append(precision)\n","        metrics_dict['Recall'].append(recall)\n","        metrics_dict['F1 Score'].append(f1_score)\n","        metrics_dict['IoU'].append(iou)\n","        metrics_dict['Relative Bias'].append(rel_bias)\n","\n","metrics_df = pd.DataFrame(metrics_dict)\n","print(metrics_df)\n"]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Data from table\n","data = {\n","    'Fire Name': ['PineGulch', 'GrizzlyCreek', 'CherryCanyon', 'Decker', 'LakeChrist', 'Palateau', 'SilverCreek'],\n","    'F1 Score': [0.6664, 0.6624, 0.7307, 0.7619, 0.7178, 0.7554, 0.4765],\n","    'IoU': [0.4997, 0.4952, 0.5756, 0.6154, 0.5598, 0.6069, 0.3128],\n","    'Relative Bias': [-0.0869, -0.2065, -0.4211, -0.1373, -0.0312, -0.3386, 0.3242]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n","\n","# Plot F1 Score\n","df.plot(x='Fire Name', y='F1 Score', kind='bar', ax=axes[0], color='skyblue', legend=False)\n","axes[0].set_title('F1 Score')\n","axes[0].set_ylim(0, 1)  # Setting the limit for y axis\n","axes[0].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","# Plot IoU\n","df.plot(x='Fire Name', y='IoU', kind='bar', ax=axes[1], color='#90EE90', legend=False)\n","axes[1].set_title('IoU')\n","axes[1].set_ylim(0, 1)  # Setting the limit for y axis\n","axes[1].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","# Plot Relative Bias\n","df.plot(x='Fire Name', y='Relative Bias', kind='bar', ax=axes[2], color='salmon', legend=False)\n","axes[2].set_title('Relative Bias')\n","axes[2].set_ylim(-0.5, 0.5)  # Setting the limit for y axis\n","axes[2].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"jlYg7cpuF_Lq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Data from Case 1\n","data = {\n","    'Fire Name': ['CherryCanyon', 'GrizzlyCreek', 'PineGulch', 'SilverCreek',\n","                  'Decker', 'LakeChrist', 'Palateau'],\n","    'F1 Score': [0.8802, 0.7858, 0.7925, 0.5342, 0.9131, 0.8384, 0.8244],\n","    'IoU': [0.7861, 0.6348, 0.6263, 0.3654, 0.8446, 0.7292, 0.6959],\n","    'Relative Bias': [-0.1893, 0.1113, 0.2892, 0.8602, 0.1790, 0.3695, -0.0673]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Set up the matplotlib figure\n","fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n","\n","# Plot F1 Score\n","df.plot(x='Fire Name', y='F1 Score', kind='bar', ax=axes[0], color='skyblue', legend=False)\n","axes[0].set_title('F1 Score')\n","axes[0].set_ylim(0, 1)  # Setting the limit for y axis\n","axes[0].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","# Plot IoU\n","df.plot(x='Fire Name', y='IoU', kind='bar', ax=axes[1], color='#90EE90', legend=False)\n","axes[1].set_title('IoU')\n","axes[1].set_ylim(0, 1)  # Setting the limit for y axis\n","axes[1].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","# Plot Relative Bias\n","df.plot(x='Fire Name', y='Relative Bias', kind='bar', ax=axes[2], color='salmon', legend=False)\n","axes[2].set_title('Relative Bias')\n","axes[2].set_ylim(-1, 1)  # Adjusted limit to accommodate the full range of your new data\n","axes[2].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"PB9niETqT1oI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Data from Case 2&3\n","data = {\n","    'Fire Name': ['CherryCanyon', 'GrizzlyCreek', 'PineGulch', 'SilverCreek',\n","                  'Decker', 'LakeChrist', 'Palateau'],\n","    'F1 Score': [0.6038, 0.5661, 0.6020, 0.4785, 0.6240, 0.6337, 0.6458],\n","    'IoU': [0.4324, 0.3948, 0.4306, 0.3145, 0.4534, 0.4638, 0.4769],\n","    'Relative Bias': [-0.5647, -0.4034, -0.3135, -0.0045, -0.3450, -0.2761, -0.5028]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Set up the matplotlib figure\n","fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n","\n","# Plot F1 Score\n","df.plot(x='Fire Name', y='F1 Score', kind='bar', ax=axes[0], color='skyblue', legend=False)\n","axes[0].set_title('F1 Score')\n","axes[0].set_ylim(0, 1)  # Setting the limit for y axis\n","axes[0].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","# Plot IoU\n","df.plot(x='Fire Name', y='IoU', kind='bar', ax=axes[1], color='#90EE90', legend=False)\n","axes[1].set_title('IoU')\n","axes[1].set_ylim(0, 1)  # Setting the limit for y axis\n","axes[1].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","# Plot Relative Bias\n","df.plot(x='Fire Name', y='Relative Bias', kind='bar', ax=axes[2], color='salmon', legend=False)\n","axes[2].set_title('Relative Bias')\n","axes[2].set_ylim(-1, 1)  # Adjusted limit to accommodate the range of bias data\n","axes[2].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"_g9TBQOOU5Cz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Data from Case 4\n","data = {\n","    'Fire Name': ['CherryCanyon', 'GrizzlyCreek', 'PineGulch', 'SilverCreek',\n","                  'Decker', 'LakeChrist', 'Palateau'],\n","    'F1 Score': [0.9453, 0.7117, 0.8594, 0.7658, 0.7716, 0.5734, 0.7696],\n","    'IoU': [0.8963, 0.5525, 0.7535, 0.6205, 0.6282, 0.4019, 0.6254],\n","    'Relative Bias': [-0.0762, 0.2023, 0.1118, 0.0538, -0.2590, -0.4774, -0.3187]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Set up the matplotlib figure\n","fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n","\n","# Plot F1 Score\n","df.plot(x='Fire Name', y='F1 Score', kind='bar', ax=axes[0], color='skyblue', legend=False)\n","axes[0].set_title('F1 Score')\n","axes[0].set_ylim(0, 1)  # Setting the limit for y axis\n","axes[0].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","# Plot IoU\n","df.plot(x='Fire Name', y='IoU', kind='bar', ax=axes[1], color='#90EE90', legend=False)\n","axes[1].set_title('IoU')\n","axes[1].set_ylim(0, 1)  # Setting the limit for y axis\n","axes[1].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","# Plot Relative Bias\n","df.plot(x='Fire Name', y='Relative Bias', kind='bar', ax=axes[2], color='salmon', legend=False)\n","axes[2].set_title('Relative Bias')\n","axes[2].set_ylim(-0.5, 0.5)  # Adjusted limit to accommodate the range of bias data\n","axes[2].set_xticklabels(df['Fire Name'], rotation=45, ha='right')  # Rotate x-axis labels by 45 degrees\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"HAEb7ymHVWfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Data Setup\n","fire_names = ['CherryCanyon', 'GrizzlyCreek', 'PineGulch', 'SilverCreek',\n","              'Decker', 'LakeChrist', 'Palateau']\n","cases = ['Case 1', 'Case 2&3', 'Case 4', 'Case 5']\n","\n","# IoU data for each case and fire\n","iou_data = {\n","    'Fire Name': fire_names,\n","    'Case 1': [0.7861, 0.6348, 0.6263, 0.3654, 0.8446, 0.7292, 0.6959],\n","    'Case 2&3': [0.4324, 0.3948, 0.4306, 0.3145, 0.4534, 0.4638, 0.4769],\n","    'Case 4': [0.8963, 0.5525, 0.7535, 0.6205, 0.6282, 0.4019, 0.6254],\n","    'Case 5': [0.5756, 0.4952, 0.4997, 0.3128, 0.6154, 0.5598, 0.6069]\n","}\n","\n","# Relative Bias data for each case and fire\n","relative_bias_data = {\n","    'Fire Name': fire_names,\n","    'Case 1': [-0.1893, 0.1113, 0.2892, 0.8602, 0.1790, 0.3695, -0.0673],\n","    'Case 2&3': [-0.5647, -0.4034, -0.3135, -0.0045, -0.3450, -0.2761, -0.5028],\n","    'Case 4': [-0.0762, 0.2023, 0.1118, 0.0538, -0.2590, -0.4774, -0.3187],\n","    'Case 5': [-0.4211, -0.2065, -0.0869, 0.3242, -0.1373, -0.0312, -0.3386]\n","}\n","\n","# F1 Score data for each case and fire\n","f1_score_data = {\n","    'Fire Name': fire_names,\n","    'Case 1': [0.8802, 0.7858, 0.7925, 0.5342, 0.9131, 0.8384, 0.8244],\n","    'Case 2&3': [0.6038, 0.5661, 0.6020, 0.4785, 0.6240, 0.6337, 0.6458],\n","    'Case 4': [0.9453, 0.7117, 0.8594, 0.7658, 0.7716, 0.5734, 0.7696],\n","    'Case 5': [0.7307, 0.6624, 0.6664, 0.4765, 0.7619, 0.7178, 0.7554]\n","}\n","\n","# Creating DataFrames\n","iou_df = pd.DataFrame(iou_data)\n","relative_bias_df = pd.DataFrame(relative_bias_data)\n","f1_score_df = pd.DataFrame(f1_score_data)\n","\n","# plot and save figure\n","def plot_and_save(df, metric_name, filename):\n","    plt.figure(figsize=(10, 6))\n","    for index, row in df.iterrows():\n","        plt.plot(cases, row[1:], marker='o', label=row['Fire Name'])\n","    plt.title(f'{metric_name} Scores Across Cases')\n","    plt.xlabel('Case')\n","    plt.ylabel(metric_name)\n","    plt.legend(title='Fire Name')\n","    plt.grid(True)\n","    plt.tight_layout()\n","    plt.savefig(f\"{filename}.png\")\n","    plt.close()\n","\n","# Plotting and saving each graph\n","plot_and_save(iou_df, 'IoU', 'iou_scores')\n","plot_and_save(relative_bias_df, 'Relative Bias', 'relative_bias_scores')\n","plot_and_save(f1_score_df, 'F1 Score', 'f1_scores')"],"metadata":{"id":"lNYmOUwZG4Au"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["JbNIyWoBX5Ib","-2bSGHu-2dQu","axVuqGaBMk0d","bZcp34wRwn0-"],"machine_shape":"hm","provenance":[],"mount_file_id":"1cyEUfGqw5eSrZntEIMV_NhrIj_oPLrLf","authorship_tag":"ABX9TyPGo7mIiHC7r7o+njt7nU6D"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}